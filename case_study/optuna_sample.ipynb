{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6928,
     "status": "ok",
     "timestamp": 1710130965578,
     "user": {
      "displayName": "Pedro Braga",
      "userId": "06312252049019718671"
     },
     "user_tz": 180
    },
    "id": "-0mo3Ox0iCrS",
    "outputId": "d0ee05e9-75bd-43a2-8d8a-38ceac463a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (24.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (2.0.28)\n",
      "Requirement already satisfied: tqdm in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (4.66.2)\n",
      "Requirement already satisfied: PyYAML in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (7.0.2)\n",
      "Requirement already satisfied: importlib-resources in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "id": "TfN6CFGhhxQx",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/miniconda3/envs/op297/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-06 13:53:15.406167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.backend import clear_session\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPool1D, Dense, Flatten, Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 10\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1dU2GwEKtp_"
   },
   "source": [
    "Função auxiliar para obtenção e separação dos dados em `train`, `test` e `valid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t1dU2GwEKtp_"
   },
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    img_x, img_y = x_test.shape[1], x_test.shape[2]\n",
    "    x_train = x_train.reshape(-1, img_x, img_y, 1).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, img_x, img_y, 1).astype(\"float32\") / 255\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                      test_size=0.05)\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVAn4fC2K361"
   },
   "source": [
    "Funções auxiliares para definição do espaço de busca paramétrico:\n",
    "\n",
    "\n",
    "*   `get_config`: hiperparametrocos base, comum a todos os modelos\n",
    "*   `get_cnn_config`: parâmetros específicos para modelo convolucional\n",
    "*   `get_mlp_config`: parâmetros específicos para modelo totalmente conectado\n",
    "\n",
    "Utiliza-se o objeto `trial`, que é instanciado e obtido após a chamada do `study.optimize`. O `trial` fornece funções como `suggest_float`, `suggest_categorical`, `suggest_int`, etc. Estas funções devem ser utilizadas de acordo com a característica do parâmetro a ser amostrado, e podem receber um range min/max do valores do parâmetro ou uma lista de categorias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vVAn4fC2K361"
   },
   "outputs": [],
   "source": [
    "'''  \n",
    "Funções auxiliares para definição do espaço de busca paramétrico:  \n",
    "  * `get_config`: hiperparametrocos base, comum a todos os modelos  \n",
    "  * `get_mlp_config`: parâmetros específicos para modelo totalmente conectado  \n",
    "Utiliza-se o objeto `trial`, que é instanciado e obtido após a chamada do `study.optimize`. O `trial` fornece funções como `suggest_float`, `suggest_categorical`, `suggest_int`, etc. Estas funções devem ser utilizadas de acordo com a característica do parâmetro a ser amostrado, e podem receber um range min/max do valores do parâmetro ou uma lista de categorias.  \n",
    "''' \n",
    "\n",
    "def get_config(trial):\n",
    "  config = {\n",
    "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1),\n",
    "      \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128, 256]),\n",
    "      \"optimizer\": trial.suggest_categorical(\"optimizer\", [0, 1, 2]),\n",
    "      \"activation\": trial.suggest_categorical(\"activation\",\n",
    "       [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "      \"activation_out\": trial.suggest_categorical(\"activation_out\",\n",
    "       [\"softmax\", \"sigmoid\"]),\n",
    "  }\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def get_cnn_config(trial):\n",
    "  config = get_config(trial)\n",
    "  config[\"n_hidden\"] = trial.suggest_int(\"n_hidden\", 1, 2)\n",
    "  config[\"kernel_1\"] = trial.suggest_categorical(\"kernel_1\", [3, 5])\n",
    "  config[\"kernel_2\"] = trial.suggest_categorical(\"kernel_2\", [3, 5])\n",
    "  config[\"filters\"] = trial.suggest_categorical(\"filters\", [32, 64])\n",
    "  config[\"stride\"] = trial.suggest_categorical(\"stride\", [1, 2])\n",
    "  config[\"pool_size\"] = trial.suggest_categorical(\"pool_size\", [3, 5])\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def get_mlp_config(trial):\n",
    "  config = get_config(trial)\n",
    "  config[\"n_layers\"] = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "  for l in range(config[\"n_layers\"]):\n",
    "    config[f\"n_neurons_{l}\"] = trial.suggest_int(f\"n_neurons_{l}\", 16, 1024)\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def get_optimizer(config):\n",
    "    possible_optims = [\n",
    "        tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"]),\n",
    "        tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
    "        tf.keras.optimizers.RMSprop(learning_rate=config[\"learning_rate\"]),\n",
    "    ]\n",
    "\n",
    "    return possible_optims[config[\"optimizer\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8s2TnzCKbT3"
   },
   "source": [
    "Funções auxiliares para definição de dois modelos base:\n",
    "\n",
    "*   Convolucional (`get_cnn`)\n",
    "*   Totalmente conectado (`get_mlp`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "273smTUIrPO3"
   },
   "outputs": [],
   "source": [
    "def get_cnn(input_shape, config):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(\n",
    "            filters=config[\"filters\"],\n",
    "            kernel_size=config[\"kernel_1\"],\n",
    "            activation=config[\"activation\"])\n",
    "    )\n",
    "    model.add(Conv1D(\n",
    "        filters=config[\"filters\"],\n",
    "        kernel_size=config[\"kernel_2\"],\n",
    "        activation=config[\"activation\"],)\n",
    "    )\n",
    "    model.add(MaxPool1D(pool_size=config[\"pool_size\"]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mstS0zPq1GR0"
   },
   "outputs": [],
   "source": [
    "def get_mlp(config):\n",
    "  model = Sequential()\n",
    "  model.add(Flatten())\n",
    "  print(config.keys())\n",
    "  for l in range(config[\"n_layers\"]):\n",
    "    model.add(Dense(config[f\"n_neurons_{l}\"], activation=config[\"activation\"]))\n",
    "  model.add(Dense(CLASSES, activation=config[\"activation_out\"]))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAx8yMY7KVvY"
   },
   "source": [
    "### Definição da função objetivo\n",
    "1. Obter os dados;\n",
    "2. Definir configurações de espaço de busca paramêtrico;\n",
    "3. Definir o modelo;\n",
    "4. Treinar e avaliar;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r24lJlNmbgks"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    clear_session()\n",
    "\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = get_mnist()\n",
    "\n",
    "    # input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "    # configs = get_cnn_config(trial)\n",
    "    # model = get_cnn(input_shape, configs)\n",
    "\n",
    "    configs = get_mlp_config(trial)\n",
    "    model = get_mlp(configs)\n",
    "\n",
    "    optimizer = get_optimizer(configs)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    monitor = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-4,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        shuffle=True,\n",
    "        batch_size=configs[\"batch_size\"],\n",
    "        epochs=EPOCHS,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    return model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrJdnLZgHms4"
   },
   "source": [
    "# Criação\n",
    "\n",
    "1.   Criar um [`optuna.Study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study), utilizando a função [`create_study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.create_study.html).\n",
    "\n",
    "  *   Um estudo corresponde a uma tarefa de otimização, i.e., um conjunto de tentativas.\n",
    "\n",
    "\n",
    "2.   Definir uma função objetivo a ser otimizada, através da chamada do método [`optimize`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize) do objeto `optuna.Study`\n",
    "   *   Definir os principais parametros como: função a ser otimizada (`objective`), número de tentativas (`n_trials`), número de jobs paralelos (`n_jobs`), etc.\n",
    "\n",
    "   *   A função objetivo será executava `n_trials` vezes, até a conclusão da otimização como foi definida.\n",
    "\n",
    "3. Plotar o gráfico de importância dos parâmetros através do [`plot_param_importances`](https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_param_importances.html) do pacote `optuna.visualization`\n",
    "\n",
    "4. Tratar o dataframe final e salvar os resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b19e92ffd929457fa2f9b00adfadc22d",
      "c62a84f300ee40f38cfcf8627059a295",
      "6652cc9bc6164d0385b2c57c3a41269f",
      "2cf53f266da242daaf6e3af89560bb7e",
      "6d1df215490c432297f7f783b6cefc8d",
      "c6027eec729b40d98401d766ff0a90ac",
      "8183f0f24ebc4a099e7170da3557ecf2",
      "6d4ee057b82346d78ffed0f23219e017",
      "dc3bdcb9eaf140a1995ab621b9e21f1b",
      "b8a61a4845a34a3fb66cab88b6d0ec37",
      "5951c2490dcd43fba7d8cead084c5938"
     ]
    },
    "executionInfo": {
     "elapsed": 795085,
     "status": "ok",
     "timestamp": 1710131899671,
     "user": {
      "displayName": "Pedro Braga",
      "userId": "06312252049019718671"
     },
     "user_tz": 180
    },
    "id": "6m5tijJXzUmD",
    "outputId": "3dbb5884-3c15-4476-a11d-7186fd6ecafd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 13:53:16,517] A new study created in memory with name: no-name-c2ccd80c-4727-4deb-836a-8ba839b834b6\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 13:53:18.696557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.710261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.710632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.745481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.745761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.745883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.818584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.818743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.818869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 13:53:18.818969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10215 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 13:53:43.135033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-04-06 13:53:43.168447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96e0231390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-06 13:53:43.168475: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2024-04-06 13:53:43.439954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-04-06 13:53:43.522533: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-04-06 13:53:44.503030: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3563 [..............................] - ETA: 20:22:29 - loss: 2.3330 - accuracy: 0.0000e+00WARNING:tensorflow:5 out of the last 49 calls to <function Model.make_train_function.<locals>.train_function at 0x7f978c6b8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "   4/3563 [..............................] - ETA: 4:51 - loss: 7.1307 - accuracy: 0.1094WARNING:tensorflow:6 out of the last 50 calls to <function Model.make_train_function.<locals>.train_function at 0x7f978c437790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "223/223 [==============================] - 34s 82ms/step - loss: 1.2563 - accuracy: 0.6529 - val_loss: 0.7248 - val_accuracy: 0.8167\n",
      "223/223 [==============================] - 34s 82ms/step - loss: 0.8229 - accuracy: 0.8002 - val_loss: 0.5047 - val_accuracy: 0.8747\n",
      "200/223 [=========================>....] - ETA: 1s - loss: 253.9877 - accuracy: 0.3897Epoch 2/15\n",
      " 200/3563 [>.............................] - ETA: 3:14 - loss: 1.1793 - accuracy: 0.7128Epoch 2/15\n",
      "223/223 [==============================] - 35s 80ms/step - loss: 12.9752 - accuracy: 0.8341 - val_loss: 0.7310 - val_accuracy: 0.8530\n",
      "247/446 [===============>..............] - ETA: 12s - loss: 2.2900 - accuracy: 0.7081Epoch 2/15\n",
      "223/223 [==============================] - 35s 72ms/step - loss: 2.2118 - accuracy: 0.3103 - val_loss: 2.1036 - val_accuracy: 0.4950\n",
      "249/446 [===============>..............] - ETA: 11s - loss: 2.2753 - accuracy: 0.7092Epoch 2/15\n",
      "223/223 [==============================] - 37s 67ms/step - loss: 1.9359 - accuracy: 0.5993 - val_loss: 0.2191 - val_accuracy: 0.9347\n",
      "220/223 [============================>.] - ETA: 0s - loss: 2.6954 - accuracy: 0.7159Epoch 2/15\n",
      "223/223 [==============================] - 37s 70ms/step - loss: 4.1027 - accuracy: 0.3107 - val_loss: 1.5188 - val_accuracy: 0.3843\n",
      "272/446 [=================>............] - ETA: 10s - loss: 0.3492 - accuracy: 0.8986Epoch 2/15\n",
      "223/223 [==============================] - 38s 71ms/step - loss: 228.2704 - accuracy: 0.3982 - val_loss: 1.1790 - val_accuracy: 0.4810\n",
      " 53/223 [======>.......................] - ETA: 12s - loss: 0.4790 - accuracy: 0.8791Epoch 2/15\n",
      "223/223 [==============================] - 38s 69ms/step - loss: 0.5270 - accuracy: 0.8618 - val_loss: 0.2873 - val_accuracy: 0.9153\n",
      " 294/1782 [===>..........................] - ETA: 1:34 - loss: 0.6906 - accuracy: 0.8126Epoch 2/15\n",
      "223/223 [==============================] - 39s 68ms/step - loss: 2.6682 - accuracy: 0.7178 - val_loss: 0.4755 - val_accuracy: 0.8673\n",
      "  8/223 [>.............................] - ETA: 13s - loss: 0.3200 - accuracy: 0.9023Epoch 2/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.5735 - accuracy: 0.8555 - val_loss: 0.4875 - val_accuracy: 0.8687\n",
      " 458/1782 [======>.......................] - ETA: 1:18 - loss: 0.4823 - accuracy: 0.8590Epoch 3/15\n",
      "446/446 [==============================] - 49s 74ms/step - loss: 0.5633 - accuracy: 0.8579 - val_loss: 0.3822 - val_accuracy: 0.8983\n",
      " 453/3563 [==>...........................] - ETA: 3:10 - loss: 1.4769 - accuracy: 0.7110Epoch 2/15\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 0.4391 - accuracy: 0.8847 - val_loss: 0.4048 - val_accuracy: 0.8907\n",
      "462/891 [==============>...............] - ETA: 26s - loss: 1.5820 - accuracy: 0.6564Epoch 3/15\n",
      "446/446 [==============================] - 50s 65ms/step - loss: 0.2898 - accuracy: 0.9153 - val_loss: 0.1461 - val_accuracy: 0.9583\n",
      "502/891 [===============>..............] - ETA: 24s - loss: 5.5130 - accuracy: 0.8365Epoch 2/15\n",
      "446/446 [==============================] - 50s 65ms/step - loss: 0.3162 - accuracy: 0.9109 - val_loss: 0.2378 - val_accuracy: 0.9330\n",
      " 478/3563 [===>..........................] - ETA: 3:09 - loss: 72.3881 - accuracy: 0.0985Epoch 2/15\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 0.5031 - accuracy: 0.9079 - val_loss: 0.4349 - val_accuracy: 0.8650\n",
      "446/446 [==============================] - 50s 65ms/step - loss: 0.2505 - accuracy: 0.9259 - val_loss: 0.1193 - val_accuracy: 0.9650\n",
      "190/223 [========================>.....] - ETA: 2s - loss: 1.3892 - accuracy: 0.4410Epoch 3/15\n",
      "195/223 [=========================>....] - ETA: 1s - loss: 0.3424 - accuracy: 0.8998Epoch 2/15\n",
      "446/446 [==============================] - 50s 68ms/step - loss: 2.1798 - accuracy: 0.2550 - val_loss: 2.0085 - val_accuracy: 0.4947\n",
      "446/446 [==============================] - 50s 66ms/step - loss: 0.5013 - accuracy: 0.8494 - val_loss: 0.5386 - val_accuracy: 0.8490\n",
      "212/223 [===========================>..] - ETA: 0s - loss: 1.4609 - accuracy: 0.3979890Epoch 2/15\n",
      " 483/1782 [=======>......................] - ETA: 1:23 - loss: 2.2359 - accuracy: 0.2140Epoch 2/15\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 1.9341 - accuracy: 0.5915 - val_loss: 1.7344 - val_accuracy: 0.5967\n",
      " 476/1782 [=======>......................] - ETA: 1:20 - loss: 0.4359 - accuracy: 0.8718Epoch 3/15\n",
      "446/446 [==============================] - 51s 68ms/step - loss: 1.4734 - accuracy: 0.7847 - val_loss: 0.9286 - val_accuracy: 0.8003\n",
      "  9/446 [..............................] - ETA: 36s - loss: 0.1858 - accuracy: 0.9427Epoch 2/15\n",
      "223/223 [==============================] - 15s 65ms/step - loss: 0.1888 - accuracy: 0.9429 - val_loss: 0.1831 - val_accuracy: 0.9367\n",
      " 468/3563 [==>...........................] - ETA: 3:09 - loss: 4.3158 - accuracy: 0.0967Epoch 3/15\n",
      "446/446 [==============================] - 51s 67ms/step - loss: 2.2950 - accuracy: 0.1383 - val_loss: 2.2740 - val_accuracy: 0.2103\n",
      "523/891 [================>.............] - ETA: 23s - loss: 5.3230 - accuracy: 0.8385Epoch 2/15\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 1.4517 - accuracy: 0.4024 - val_loss: 1.2490 - val_accuracy: 0.5140\n",
      " 504/1782 [=======>......................] - ETA: 1:17 - loss: 0.9987 - accuracy: 0.7768Epoch 3/15\n",
      "446/446 [==============================] - 52s 68ms/step - loss: 0.4508 - accuracy: 0.8784 - val_loss: 0.3191 - val_accuracy: 0.9093\n",
      " 507/3563 [===>..........................] - ETA: 3:08 - loss: 1.4121 - accuracy: 0.7239Epoch 2/15\n",
      "223/223 [==============================] - 14s 65ms/step - loss: 0.3604 - accuracy: 0.8949 - val_loss: 0.3810 - val_accuracy: 0.8990\n",
      " 444/3563 [==>...........................] - ETA: 3:20 - loss: 2.5641 - accuracy: 0.0987Epoch 3/15\n",
      "223/223 [==============================] - 15s 66ms/step - loss: 1.3774 - accuracy: 0.4441 - val_loss: 1.2094 - val_accuracy: 0.4483\n",
      " 489/1782 [=======>......................] - ETA: 1:20 - loss: 2.3660 - accuracy: 0.5942Epoch 3/15\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 0.6904 - accuracy: 0.7991 - val_loss: 0.7872 - val_accuracy: 0.7693\n",
      " 449/1782 [======>.......................] - ETA: 1:26 - loss: 6.9010 - accuracy: 0.1462Epoch 3/15\n",
      "446/446 [==============================] - 56s 69ms/step - loss: 2.3432 - accuracy: 0.1016 - val_loss: 2.3594 - val_accuracy: 0.1037\n",
      " 569/1782 [========>.....................] - ETA: 1:13 - loss: 0.9455 - accuracy: 0.7842Epoch 2/15\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 0.4552 - accuracy: 0.8772 - val_loss: 0.4156 - val_accuracy: 0.8867\n",
      " 659/3563 [====>.........................] - ETA: 2:56 - loss: 4.2881 - accuracy: 0.0957Epoch 4/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.3759 - accuracy: 0.8968 - val_loss: 0.3638 - val_accuracy: 0.8967\n",
      "722/891 [=======================>......] - ETA: 10s - loss: 0.2795 - accuracy: 0.9161Epoch 4/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.3953 - accuracy: 0.9232 - val_loss: 0.4462 - val_accuracy: 0.9217\n",
      "762/891 [========================>.....] - ETA: 8s - loss: 0.4465 - accuracy: 0.8834Epoch 4/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.4974 - accuracy: 0.7055 - val_loss: 1.2800 - val_accuracy: 0.7420\n",
      " 29/223 [==>...........................] - ETA: 11s - loss: 0.4169 - accuracy: 0.8878Epoch 4/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.1187 - accuracy: 0.9630 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
      " 632/3563 [====>.........................] - ETA: 3:05 - loss: 15.9933 - accuracy: 0.1004Epoch 4/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.1919 - accuracy: 0.5076 - val_loss: 1.1382 - val_accuracy: 0.5307\n",
      "257/446 [================>.............] - ETA: 10s - loss: 0.4055 - accuracy: 0.897501Epoch 4/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.5522 - accuracy: 0.8390 - val_loss: 0.5530 - val_accuracy: 0.8443\n",
      "717/891 [=======================>......] - ETA: 10s - loss: 22.3065 - accuracy: 0.1006Epoch 4/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.2996 - accuracy: 0.4664 - val_loss: 1.1692 - val_accuracy: 0.4613\n",
      " 752/3563 [=====>........................] - ETA: 2:54 - loss: 0.4544 - accuracy: 0.8720Epoch 4/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.9440 - accuracy: 0.7504 - val_loss: 0.8802 - val_accuracy: 0.7700\n",
      " 771/1782 [===========>..................] - ETA: 1:00 - loss: 0.8388 - accuracy: 0.8029Epoch 4/15\n",
      "891/891 [==============================] - 75s 67ms/step - loss: 0.4220 - accuracy: 0.8890 - val_loss: 0.2882 - val_accuracy: 0.9220\n",
      " 881/1782 [=============>................] - ETA: 54s - loss: 0.3829 - accuracy: 0.8871Epoch 2/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.3501 - accuracy: 0.9011 - val_loss: 0.3401 - val_accuracy: 0.9020\n",
      "891/891 [==============================] - 76s 64ms/step - loss: 3.4284 - accuracy: 0.8569 - val_loss: 0.7548 - val_accuracy: 0.9017\n",
      "148/223 [==================>...........] - ETA: 4s - loss: 0.6359 - accuracy: 0.8169Epoch 3/15\n",
      "169/223 [=====================>........] - ETA: 3s - loss: 1.1240 - accuracy: 0.5401Epoch 2/15\n",
      "891/891 [==============================] - 76s 63ms/step - loss: 0.4285 - accuracy: 0.8846 - val_loss: 0.2788 - val_accuracy: 0.9200\n",
      " 820/3563 [=====>........................] - ETA: 2:51 - loss: 15.3404 - accuracy: 0.0993Epoch 2/15\n",
      "891/891 [==============================] - 76s 64ms/step - loss: 0.2583 - accuracy: 0.9223 - val_loss: 0.1686 - val_accuracy: 0.9553\n",
      " 899/3563 [======>.......................] - ETA: 2:38 - loss: 0.6514 - accuracy: 0.8229Epoch 2/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.3442 - accuracy: 0.9044 - val_loss: 0.3390 - val_accuracy: 0.9047\n",
      "165/223 [=====================>........] - ETA: 3s - loss: 0.6314 - accuracy: 0.8191Epoch 5/15\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 0.4069 - accuracy: 0.8865 - val_loss: 0.3728 - val_accuracy: 0.8953\n",
      " 913/1782 [==============>...............] - ETA: 52s - loss: 0.3814 - accuracy: 0.8872Epoch 5/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.2160 - accuracy: 0.9392 - val_loss: 0.2472 - val_accuracy: 0.9387\n",
      "889/891 [============================>.] - ETA: 0s - loss: 21.0022 - accuracy: 0.103365Epoch 3/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.3901 - accuracy: 0.9005 - val_loss: 0.4187 - val_accuracy: 0.9123\n",
      "  4/446 [..............................] - ETA: 29s - loss: 0.2345 - accuracy: 0.9316Epoch 3/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.4631 - accuracy: 0.8644 - val_loss: 0.5159 - val_accuracy: 0.8640\n",
      " 14/223 [>.............................] - ETA: 12s - loss: 0.3566 - accuracy: 0.8984Epoch 3/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 0.1263 - accuracy: 0.9619 - val_loss: 0.1538 - val_accuracy: 0.9553\n",
      " 38/446 [=>............................] - ETA: 21s - loss: 0.3455 - accuracy: 0.9021Epoch 3/15\n",
      "446/446 [==============================] - 27s 62ms/step - loss: 0.0984 - accuracy: 0.9691 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
      " 866/3563 [======>.......................] - ETA: 2:44 - loss: 0.7895 - accuracy: 0.7986Epoch 3/15\n",
      "891/891 [==============================] - 78s 64ms/step - loss: 0.9262 - accuracy: 0.7913 - val_loss: 0.1565 - val_accuracy: 0.9537\n",
      " 40/891 [>.............................] - ETA: 46s - loss: 0.5948 - accuracy: 0.9090Epoch 2/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.3791 - accuracy: 0.9303 - val_loss: 0.3067 - val_accuracy: 0.9300\n",
      "  1/891 [..............................] - ETA: 51s - loss: 0.0664 - accuracy: 0.9844Epoch 5/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 1.5951 - accuracy: 0.6005 - val_loss: 1.2171 - val_accuracy: 0.6913\n",
      "  4/891 [..............................] - ETA: 47s - loss: 0.1197 - accuracy: 0.9688 Epoch 3/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.0870 - accuracy: 0.9729 - val_loss: 0.1781 - val_accuracy: 0.9437\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 1.0984 - accuracy: 0.7727 - val_loss: 0.9665 - val_accuracy: 0.7807\n",
      " 63/891 [=>............................] - ETA: 48s - loss: 0.2639 - accuracy: 0.9251Epoch 5/15\n",
      "217/223 [============================>.] - ETA: 0s - loss: 1.1267 - accuracy: 0.5409Epoch 5/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 2.2481 - accuracy: 0.2437 - val_loss: 2.2065 - val_accuracy: 0.2597\n",
      " 972/1782 [===============>..............] - ETA: 47s - loss: 0.3435 - accuracy: 0.8978Epoch 3/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 0.2736 - accuracy: 0.9200 - val_loss: 0.2566 - val_accuracy: 0.9300\n",
      "397/446 [=========================>....] - ETA: 2s - loss: 2.3416 - accuracy: 0.1037879Epoch 3/15\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 1.1229 - accuracy: 0.5425 - val_loss: 1.0703 - val_accuracy: 0.5483\n",
      " 48/223 [=====>........................] - ETA: 10s - loss: 0.3876 - accuracy: 0.8905Epoch 5/15\n",
      "891/891 [==============================] - 81s 66ms/step - loss: 20.9961 - accuracy: 0.1033 - val_loss: 22.9824 - val_accuracy: 0.1043\n",
      " 885/1782 [=============>................] - ETA: 57s - loss: 7.1064 - accuracy: 0.12310Epoch 2/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 1.2121 - accuracy: 0.4873 - val_loss: 1.2485 - val_accuracy: 0.4837\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 0.6111 - accuracy: 0.8258 - val_loss: 0.7082 - val_accuracy: 0.8007\n",
      " 886/1782 [=============>................] - ETA: 56s - loss: 7.1090 - accuracy: 0.12310Epoch 5/15\n",
      "1001/1782 [===============>..............] - ETA: 47s - loss: 0.4129 - accuracy: 0.8850Epoch 5/15\n",
      "891/891 [==============================] - 81s 65ms/step - loss: 22.2617 - accuracy: 0.1015 - val_loss: 18.3646 - val_accuracy: 0.0973\n",
      " 45/446 [==>...........................] - ETA: 25s - loss: 0.0686 - accuracy: 0.9774100Epoch 2/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 1.4072 - accuracy: 0.6911 - val_loss: 1.0272 - val_accuracy: 0.7170\n",
      " 967/3563 [=======>......................] - ETA: 2:37 - loss: 4.2601 - accuracy: 0.0963Epoch 5/15\n",
      "891/891 [==============================] - 84s 66ms/step - loss: 14.4462 - accuracy: 0.1134 - val_loss: 12.9076 - val_accuracy: 0.0907\n",
      "1030/1782 [================>.............] - ETA: 45s - loss: 0.4585 - accuracy: 0.8728Epoch 2/15\n",
      "446/446 [==============================] - 28s 63ms/step - loss: 2.3411 - accuracy: 0.1038 - val_loss: 2.3256 - val_accuracy: 0.1083\n",
      " 94/223 [===========>..................] - ETA: 7s - loss: 0.3214 - accuracy: 0.9385Epoch 3/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.3236 - accuracy: 0.9092 - val_loss: 0.3201 - val_accuracy: 0.9097\n",
      "122/446 [=======>......................] - ETA: 17s - loss: 2.3309 - accuracy: 0.0981Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.3787 - accuracy: 0.8924 - val_loss: 0.3471 - val_accuracy: 0.9023\n",
      "1085/3563 [========>.....................] - ETA: 2:30 - loss: 0.7613 - accuracy: 0.8084Epoch 6/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.3337 - accuracy: 0.9369 - val_loss: 0.4203 - val_accuracy: 0.9410\n",
      "1137/1782 [==================>...........] - ETA: 39s - loss: 1.5840 - accuracy: 0.6513Epoch 6/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.8522 - accuracy: 0.8082 - val_loss: 0.7832 - val_accuracy: 0.8077\n",
      "299/891 [=========>....................] - ETA: 32s - loss: 0.6057 - accuracy: 0.9010Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.0694 - accuracy: 0.9783 - val_loss: 0.0758 - val_accuracy: 0.9747\n",
      "261/446 [================>.............] - ETA: 10s - loss: 0.1929 - accuracy: 0.9478Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.0758 - accuracy: 0.5692 - val_loss: 1.0148 - val_accuracy: 0.5863\n",
      "211/223 [===========================>..] - ETA: 0s - loss: 0.6636 - accuracy: 0.8138Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.1929 - accuracy: 0.5074 - val_loss: 1.1996 - val_accuracy: 0.5020\n",
      "239/891 [=======>......................] - ETA: 37s - loss: 18.2962 - accuracy: 0.0977Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.3923 - accuracy: 0.6884 - val_loss: 2.3985 - val_accuracy: 0.5373\n",
      "1238/1782 [===================>..........] - ETA: 33s - loss: 0.3818 - accuracy: 0.8928Epoch 6/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.6679 - accuracy: 0.8128 - val_loss: 0.6416 - val_accuracy: 0.8113\n",
      "300/446 [===================>..........] - ETA: 8s - loss: 0.1925 - accuracy: 0.9486Epoch 6/15\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.3177 - accuracy: 0.9098 - val_loss: 0.3203 - val_accuracy: 0.9097\n",
      "410/446 [==========================>...] - ETA: 2s - loss: 0.9850 - accuracy: 0.7556Epoch 4/15\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.3503 - accuracy: 0.9151 - val_loss: 0.5254 - val_accuracy: 0.8607\n",
      "1381/3563 [==========>...................] - ETA: 2:07 - loss: 0.6211 - accuracy: 0.8332Epoch 4/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.3603 - accuracy: 0.8977 - val_loss: 0.3375 - val_accuracy: 0.9047\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.4206 - accuracy: 0.8793 - val_loss: 0.4436 - val_accuracy: 0.8733\n",
      "402/891 [============>.................] - ETA: 27s - loss: 18.1889 - accuracy: 0.0986Epoch 7/15\n",
      "1366/1782 [=====================>........] - ETA: 25s - loss: 0.3432 - accuracy: 0.8994Epoch 4/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.3080 - accuracy: 0.9135 - val_loss: 0.3081 - val_accuracy: 0.9130\n",
      "207/223 [==========================>...] - ETA: 0s - loss: 0.3362 - accuracy: 0.9409Epoch 7/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.1944 - accuracy: 0.9484 - val_loss: 0.2137 - val_accuracy: 0.9383\n",
      "1409/1782 [======================>.......] - ETA: 21s - loss: 0.7244 - accuracy: 0.8240Epoch 4/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.0680 - accuracy: 0.9784 - val_loss: 0.0846 - val_accuracy: 0.9740\n",
      "1318/3563 [==========>...................] - ETA: 2:15 - loss: 0.7164 - accuracy: 0.8202Epoch 4/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.1215 - val_accuracy: 0.9710\n",
      "1374/3563 [==========>...................] - ETA: 2:10 - loss: 4.2492 - accuracy: 0.0952Epoch 4/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.9716 - accuracy: 0.7587 - val_loss: 0.8104 - val_accuracy: 0.7837\n",
      "1369/1782 [======================>.......] - ETA: 24s - loss: 1.4718 - accuracy: 0.6594Epoch 4/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.3385 - accuracy: 0.9409 - val_loss: 0.3258 - val_accuracy: 0.9453\n",
      "1432/1782 [=======================>......] - ETA: 20s - loss: 0.7200 - accuracy: 0.8249Epoch 7/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.7089 - accuracy: 0.8275 - val_loss: 0.6728 - val_accuracy: 0.8257\n",
      "1347/3563 [==========>...................] - ETA: 2:13 - loss: 2.4019 - accuracy: 0.0999Epoch 7/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 2.1049 - accuracy: 0.4118 - val_loss: 1.9346 - val_accuracy: 0.4630\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.0564 - accuracy: 0.9823 - val_loss: 0.0775 - val_accuracy: 0.9760\n",
      "  5/223 [..............................] - ETA: 15s - loss: 0.6395 - accuracy: 0.8391Epoch 4/15\n",
      "548/891 [=================>............] - ETA: 18s - loss: 0.6211 - accuracy: 0.901390Epoch 7/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.2278 - accuracy: 0.9344 - val_loss: 0.2229 - val_accuracy: 0.9393\n",
      "1396/1782 [======================>.......] - ETA: 23s - loss: 1.4611 - accuracy: 0.66071Epoch 4/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 1.0617 - accuracy: 0.5876 - val_loss: 1.1043 - val_accuracy: 0.5727\n",
      "206/223 [==========================>...] - ETA: 0s - loss: 0.6803 - accuracy: 0.8114Epoch 7/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 1.1688 - accuracy: 0.5218 - val_loss: 1.1292 - val_accuracy: 0.5110\n",
      "1436/1782 [=======================>......] - ETA: 20s - loss: 0.3376 - accuracy: 0.9009Epoch 7/15\n",
      "223/223 [==============================] - 13s 61ms/step - loss: 1.3192 - accuracy: 0.7035 - val_loss: 1.3386 - val_accuracy: 0.7277\n",
      "1453/1782 [=======================>......] - ETA: 19s - loss: 0.3362 - accuracy: 0.9013Epoch 7/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.6825 - accuracy: 0.8107 - val_loss: 0.7092 - val_accuracy: 0.7557\n",
      "434/891 [=============>................] - ETA: 26s - loss: 14.9912 - accuracy: 0.0997Epoch 7/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 2.3355 - accuracy: 0.1011 - val_loss: 2.3619 - val_accuracy: 0.0947\n",
      "110/446 [======>.......................] - ETA: 19s - loss: 0.3333 - accuracy: 0.91979Epoch 4/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.3477 - accuracy: 0.8999 - val_loss: 0.3370 - val_accuracy: 0.9040\n",
      "1581/3563 [============>.................] - ETA: 1:59 - loss: 0.3257 - accuracy: 0.9016Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.2956 - accuracy: 0.9163 - val_loss: 0.2957 - val_accuracy: 0.9167\n",
      "186/446 [===========>..................] - ETA: 14s - loss: 0.2020 - accuracy: 0.9428Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.2953 - accuracy: 0.9439 - val_loss: 0.4101 - val_accuracy: 0.9300\n",
      "1647/3563 [============>.................] - ETA: 1:54 - loss: 0.3607 - accuracy: 0.8969Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.1116 - val_accuracy: 0.9677\n",
      "1654/3563 [============>.................] - ETA: 1:51 - loss: 0.6014 - accuracy: 0.8398Epoch 8/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.6199 - accuracy: 0.8432 - val_loss: 0.5993 - val_accuracy: 0.8407\n",
      "200/223 [=========================>....] - ETA: 1s - loss: 0.6288 - accuracy: 0.8314Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.9209 - accuracy: 0.6660 - val_loss: 0.7661 - val_accuracy: 0.7330\n",
      "269/446 [=================>............] - ETA: 10s - loss: 0.7352 - accuracy: 0.8098Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 1.1472 - accuracy: 0.5338 - val_loss: 1.1719 - val_accuracy: 0.5117\n",
      "300/446 [===================>..........] - ETA: 8s - loss: 0.3833 - accuracy: 0.8909Epoch 8/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.6221 - accuracy: 0.8334 - val_loss: 0.5160 - val_accuracy: 0.8740\n",
      " 14/223 [>.............................] - ETA: 11s - loss: 1.2389 - accuracy: 0.5067Epoch 8/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 1.2331 - accuracy: 0.7191 - val_loss: 1.6689 - val_accuracy: 0.5990\n",
      " 98/223 [============>.................] - ETA: 7s - loss: 0.3369 - accuracy: 0.9034Epoch 8/15\n",
      "891/891 [==============================] - 52s 58ms/step - loss: 0.6342 - accuracy: 0.9048 - val_loss: 0.7359 - val_accuracy: 0.9173\n",
      "443/446 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9153Epoch 3/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 0.2342 - accuracy: 0.9349 - val_loss: 0.2167 - val_accuracy: 0.9390\n",
      "  9/891 [..............................] - ETA: 1:01 - loss: 0.3556 - accuracy: 0.9392Epoch 3/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.3003 - accuracy: 0.9154 - val_loss: 0.3101 - val_accuracy: 0.9137\n",
      "1773/1782 [============================>.] - ETA: 0s - loss: 1.3415 - accuracy: 0.6749Epoch 5/15\n",
      "1782/1782 [==============================] - 129s 62ms/step - loss: 1.7447 - accuracy: 0.5057 - val_loss: 0.9720 - val_accuracy: 0.7843\n",
      "383/446 [========================>.....] - ETA: 3s - loss: 1.7046 - accuracy: 0.5313.Epoch 2/15\n",
      "1782/1782 [==============================] - 130s 61ms/step - loss: 0.2702 - accuracy: 0.9249 - val_loss: 0.2060 - val_accuracy: 0.9493\n",
      "155/223 [===================>..........] - ETA: 4s - loss: 0.5651 - accuracy: 0.8543Epoch 2/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 0.2118 - accuracy: 0.9393 - val_loss: 0.2210 - val_accuracy: 0.9363\n",
      "   4/1782 [..............................] - ETA: 5:13 - loss: 0.1555 - accuracy: 0.9688Epoch 3/15\n",
      "1782/1782 [==============================] - 130s 61ms/step - loss: 0.6861 - accuracy: 0.8313 - val_loss: 0.5734 - val_accuracy: 0.8550\n",
      "1783/3563 [==============>...............] - ETA: 1:47 - loss: 4.2460 - accuracy: 0.0960Epoch 2/15\n",
      "891/891 [==============================] - 54s 61ms/step - loss: 0.1303 - accuracy: 0.9613 - val_loss: 0.1465 - val_accuracy: 0.9540\n",
      "786/891 [=========================>....] - ETA: 6s - loss: 14.7763 - accuracy: 0.1007Epoch 3/15\n",
      "1782/1782 [==============================] - 131s 61ms/step - loss: 0.2684 - accuracy: 0.9202 - val_loss: 0.1728 - val_accuracy: 0.9450\n",
      "438/446 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.9195Epoch 2/15\n",
      "223/223 [==============================] - 14s 64ms/step - loss: 0.3377 - accuracy: 0.9024 - val_loss: 0.3155 - val_accuracy: 0.9110\n",
      "168/223 [=====================>........] - ETA: 3s - loss: 0.7647 - accuracy: 0.724176Epoch 9/15\n",
      "1782/1782 [==============================] - 131s 63ms/step - loss: 0.3266 - accuracy: 0.9078 - val_loss: 0.2151 - val_accuracy: 0.9383\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.1978 - accuracy: 0.9483 - val_loss: 0.2770 - val_accuracy: 0.9350\n",
      "1835/3563 [==============>...............] - ETA: 1:42 - loss: 0.5923 - accuracy: 0.8430Epoch 2/15\n",
      "137/223 [=================>............] - ETA: 5s - loss: 1.0872 - accuracy: 0.7415Epoch 5/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 0.3809 - accuracy: 0.8917 - val_loss: 0.4525 - val_accuracy: 0.8660\n",
      "1812/3563 [==============>...............] - ETA: 1:46 - loss: 0.3113 - accuracy: 0.9057Epoch 5/15\n",
      "891/891 [==============================] - 54s 60ms/step - loss: 0.1531 - accuracy: 0.9549 - val_loss: 0.2043 - val_accuracy: 0.9423\n",
      "  31/1782 [..............................] - ETA: 2:13 - loss: 0.1873 - accuracy: 0.9496Epoch 3/15\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 0.2847 - accuracy: 0.9195 - val_loss: 0.2859 - val_accuracy: 0.9187\n",
      " 29/891 [..............................] - ETA: 55s - loss: 0.1527 - accuracy: 0.9515Epoch 9/15\n",
      "446/446 [==============================] - 27s 62ms/step - loss: 0.0705 - accuracy: 0.9778 - val_loss: 0.1219 - val_accuracy: 0.9683\n",
      "446/446 [==============================] - 27s 62ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.1019 - val_accuracy: 0.9673\n",
      "1782/1782 [==============================] - 132s 62ms/step - loss: 0.3565 - accuracy: 0.8998 - val_loss: 0.1824 - val_accuracy: 0.9423\n",
      "159/223 [====================>.........] - ETA: 4s - loss: 0.6285 - accuracy: 0.8221Epoch 5/15\n",
      "1753/3563 [=============>................] - ETA: 1:50 - loss: 0.6809 - accuracy: 0.8324Epoch 5/15\n",
      "446/446 [==============================] - 29s 64ms/step - loss: 0.3423 - accuracy: 0.9194 - val_loss: 0.5208 - val_accuracy: 0.9043\n",
      "  22/1782 [..............................] - ETA: 2:04 - loss: 0.1380 - accuracy: 0.9574Epoch 2/15\n",
      " 45/446 [==>...........................] - ETA: 28s - loss: 0.3077 - accuracy: 0.9090Epoch 5/15\n",
      "446/446 [==============================] - 28s 63ms/step - loss: 0.6992 - accuracy: 0.8185 - val_loss: 0.6353 - val_accuracy: 0.8360\n",
      "193/223 [========================>.....] - ETA: 1s - loss: 0.7664 - accuracy: 0.7244950Epoch 5/15\n",
      "1782/1782 [==============================] - 133s 63ms/step - loss: 0.3143 - accuracy: 0.9079 - val_loss: 0.2781 - val_accuracy: 0.9097\n",
      "212/223 [===========================>..] - ETA: 0s - loss: 0.0382 - accuracy: 0.9874Epoch 2/15\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 0.2917 - accuracy: 0.9451 - val_loss: 0.4125 - val_accuracy: 0.9423\n",
      "1877/3563 [==============>...............] - ETA: 1:41 - loss: 0.4228 - accuracy: 0.8756Epoch 9/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 17.7455 - accuracy: 0.0995 - val_loss: 22.7613 - val_accuracy: 0.1043\n",
      " 90/891 [==>...........................] - ETA: 51s - loss: 0.1929 - accuracy: 0.944831Epoch 3/15\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.1163 - val_accuracy: 0.9717\n",
      " 62/891 [=>............................] - ETA: 51s - loss: 0.1069 - accuracy: 0.969000Epoch 9/15\n",
      "1782/1782 [==============================] - 135s 63ms/step - loss: 1.3397 - accuracy: 0.6749 - val_loss: 0.8552 - val_accuracy: 0.7503\n",
      "446/446 [==============================] - 29s 64ms/step - loss: 1.6606 - accuracy: 0.5389 - val_loss: 1.3406 - val_accuracy: 0.6053\n",
      " 76/891 [=>............................] - ETA: 47s - loss: 0.1699 - accuracy: 0.947631Epoch 2/15\n",
      "1933/3563 [===============>..............] - ETA: 1:35 - loss: 1.0480 - accuracy: 0.8195Epoch 5/15\n",
      "446/446 [==============================] - 28s 63ms/step - loss: 0.1908 - accuracy: 0.9449 - val_loss: 0.1928 - val_accuracy: 0.9463\n",
      "1865/3563 [==============>...............] - ETA: 1:43 - loss: 0.3078 - accuracy: 0.9067Epoch 5/15\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 0.5594 - accuracy: 0.8547 - val_loss: 0.5469 - val_accuracy: 0.8480\n",
      "1937/3563 [===============>..............] - ETA: 1:35 - loss: 1.0470 - accuracy: 0.8197Epoch 9/15\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 0.7646 - accuracy: 0.7252 - val_loss: 0.7302 - val_accuracy: 0.7400\n",
      "  9/446 [..............................] - ETA: 26s - loss: 1.3597 - accuracy: 0.609443Epoch 9/15\n",
      "223/223 [==============================] - 15s 66ms/step - loss: 1.1559 - accuracy: 0.5356 - val_loss: 1.2307 - val_accuracy: 0.4787\n",
      "110/891 [==>...........................] - ETA: 50s - loss: 0.1971 - accuracy: 0.9439Epoch 9/15\n",
      "891/891 [==============================] - 56s 62ms/step - loss: 21.8491 - accuracy: 0.1008 - val_loss: 21.0153 - val_accuracy: 0.1087\n",
      " 85/446 [====>.........................] - ETA: 21s - loss: 0.1748 - accuracy: 0.9527Epoch 3/15\n",
      "223/223 [==============================] - 15s 69ms/step - loss: 0.6333 - accuracy: 0.8205 - val_loss: 0.4188 - val_accuracy: 0.8983\n",
      " 109/1782 [>.............................] - ETA: 1:40 - loss: 0.5342 - accuracy: 0.8693Epoch 9/15\n",
      "223/223 [==============================] - 15s 69ms/step - loss: 1.0271 - accuracy: 0.7528 - val_loss: 0.7703 - val_accuracy: 0.7993\n",
      "149/891 [====>.........................] - ETA: 45s - loss: 0.2073 - accuracy: 0.9410Epoch 9/15\n",
      "1782/1782 [==============================] - 138s 64ms/step - loss: 0.2908 - accuracy: 0.9148 - val_loss: 0.1891 - val_accuracy: 0.9413\n",
      "1966/3563 [===============>..............] - ETA: 1:36 - loss: 0.3444 - accuracy: 0.9018Epoch 2/15\n",
      "891/891 [==============================] - 55s 62ms/step - loss: 14.9245 - accuracy: 0.1004 - val_loss: 18.1552 - val_accuracy: 0.1010\n",
      " 145/1782 [=>............................] - ETA: 1:46 - loss: 0.9398 - accuracy: 0.7901Epoch 3/15\n",
      "1782/1782 [==============================] - 139s 64ms/step - loss: 6.9631 - accuracy: 0.1125 - val_loss: 7.1012 - val_accuracy: 0.0903\n",
      "1968/3563 [===============>..............] - ETA: 1:36 - loss: 0.4135 - accuracy: 0.8778Epoch 2/15\n",
      "446/446 [==============================] - 29s 65ms/step - loss: 2.3358 - accuracy: 0.1045 - val_loss: 2.3343 - val_accuracy: 0.1067\n",
      "129/446 [=======>......................] - ETA: 19s - loss: 0.1783 - accuracy: 0.9531Epoch 5/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.3296 - accuracy: 0.9053 - val_loss: 0.3061 - val_accuracy: 0.9087\n",
      "281/891 [========>.....................] - ETA: 37s - loss: 0.5915 - accuracy: 0.9118Epoch 10/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.2753 - accuracy: 0.9220 - val_loss: 0.2764 - val_accuracy: 0.9210\n",
      "186/446 [===========>..................] - ETA: 15s - loss: 1.2487 - accuracy: 0.6324Epoch 10/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.2911 - accuracy: 0.9472 - val_loss: 0.5986 - val_accuracy: 0.8817\n",
      "143/891 [===>..........................] - ETA: 43s - loss: 13.5823 - accuracy: 0.1027Epoch 10/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.0617 - val_accuracy: 0.9817\n",
      "280/446 [=================>............] - ETA: 9s - loss: 0.0560 - accuracy: 0.9816Epoch 10/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.7544 - accuracy: 0.7259 - val_loss: 0.7637 - val_accuracy: 0.7300\n",
      "2094/3563 [================>.............] - ETA: 1:28 - loss: 4.2423 - accuracy: 0.0966Epoch 10/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.5160 - accuracy: 0.8638 - val_loss: 0.5082 - val_accuracy: 0.8560\n",
      "330/891 [==========>...................] - ETA: 31s - loss: 0.1014 - accuracy: 0.969637Epoch 10/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 1.1061 - accuracy: 0.5439 - val_loss: 1.1288 - val_accuracy: 0.5427\n",
      "346/891 [==========>...................] - ETA: 32s - loss: 0.1916 - accuracy: 0.946904Epoch 10/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.5623 - accuracy: 0.8496 - val_loss: 0.7393 - val_accuracy: 0.8117\n",
      "2162/3563 [=================>............] - ETA: 1:23 - loss: 6.6541 - accuracy: 0.6708Epoch 10/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 1.4537 - accuracy: 0.6873 - val_loss: 1.4821 - val_accuracy: 0.6407\n",
      " 362/1782 [=====>........................] - ETA: 1:24 - loss: 0.1878 - accuracy: 0.9507Epoch 10/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.2878 - accuracy: 0.9180 - val_loss: 0.2974 - val_accuracy: 0.9183\n",
      "134/223 [=================>............] - ETA: 5s - loss: 0.0276 - accuracy: 0.9910Epoch 6/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.3229 - accuracy: 0.9069 - val_loss: 0.3018 - val_accuracy: 0.9147\n",
      "168/223 [=====================>........] - ETA: 3s - loss: 0.0280 - accuracy: 0.9910Epoch 11/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.3760 - accuracy: 0.8914 - val_loss: 0.3980 - val_accuracy: 0.8950\n",
      "2179/3563 [=================>............] - ETA: 1:24 - loss: 14.9350 - accuracy: 0.1007Epoch 6/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.1870 - accuracy: 0.9514 - val_loss: 0.2903 - val_accuracy: 0.9433\n",
      " 492/1782 [=======>......................] - ETA: 1:16 - loss: 0.8704 - accuracy: 0.7920Epoch 6/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.1038 - val_accuracy: 0.9727\n",
      "166/223 [=====================>........] - ETA: 3s - loss: 0.7477 - accuracy: 0.7290Epoch 6/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.2666 - accuracy: 0.9245 - val_loss: 0.2687 - val_accuracy: 0.9223\n",
      "2206/3563 [=================>............] - ETA: 1:22 - loss: 0.6614 - accuracy: 0.8394Epoch 11/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.0506 - accuracy: 0.9834 - val_loss: 0.0860 - val_accuracy: 0.9760\n",
      "2309/3563 [==================>...........] - ETA: 1:15 - loss: 0.3876 - accuracy: 0.8853Epoch 6/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.3283 - accuracy: 0.9220 - val_loss: 0.3469 - val_accuracy: 0.9293\n",
      " 439/1782 [======>.......................] - ETA: 1:20 - loss: 0.1856 - accuracy: 0.9442Epoch 6/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.5703 - accuracy: 0.8474 - val_loss: 0.5446 - val_accuracy: 0.8443\n",
      " 376/1782 [=====>........................] - ETA: 1:20 - loss: 0.1771 - accuracy: 0.9481Epoch 6/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.2693 - accuracy: 0.9512 - val_loss: 0.4696 - val_accuracy: 0.9487\n",
      "444/446 [============================>.] - ETA: 0s - loss: 1.1492 - accuracy: 0.6569Epoch 11/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 1.1485 - accuracy: 0.6571 - val_loss: 0.9851 - val_accuracy: 0.6960\n",
      "181/223 [=======================>......] - ETA: 2s - loss: 1.0252 - accuracy: 0.7483Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.0879 - val_accuracy: 0.9793\n",
      " 547/1782 [========>.....................] - ETA: 1:13 - loss: 0.1777 - accuracy: 0.9525Epoch 11/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 0.1622 - accuracy: 0.9522 - val_loss: 0.1775 - val_accuracy: 0.9520\n",
      " 554/1782 [========>.....................] - ETA: 1:12 - loss: 0.8571 - accuracy: 0.7940Epoch 6/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.4834 - accuracy: 0.8702 - val_loss: 0.4769 - val_accuracy: 0.8613\n",
      " 65/223 [=======>......................] - ETA: 8s - loss: 0.2647 - accuracy: 0.9256Epoch 11/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.7466 - accuracy: 0.7288 - val_loss: 0.7754 - val_accuracy: 0.7147\n",
      "2386/3563 [===================>..........] - ETA: 1:09 - loss: 0.5832 - accuracy: 0.8481Epoch 11/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 1.1110 - accuracy: 0.5438 - val_loss: 1.1738 - val_accuracy: 0.4643\n",
      "594/891 [===================>..........] - ETA: 17s - loss: 0.1914 - accuracy: 0.9465Epoch 11/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.5422 - accuracy: 0.8541 - val_loss: 0.5779 - val_accuracy: 0.8567\n",
      " 82/446 [====>.........................] - ETA: 22s - loss: 0.3645 - accuracy: 0.9013Epoch 11/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 1.0368 - accuracy: 0.7461 - val_loss: 1.1874 - val_accuracy: 0.7100\n",
      "2372/3563 [==================>...........] - ETA: 1:11 - loss: 4.2340 - accuracy: 0.0977Epoch 11/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 2.3397 - accuracy: 0.1031 - val_loss: 2.3323 - val_accuracy: 0.1083\n",
      "594/891 [===================>..........] - ETA: 17s - loss: 0.1262 - accuracy: 0.9641Epoch 6/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.3175 - accuracy: 0.9088 - val_loss: 0.2998 - val_accuracy: 0.9103\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.2587 - accuracy: 0.9269 - val_loss: 0.2620 - val_accuracy: 0.9227\n",
      "151/223 [===================>..........] - ETA: 4s - loss: 0.7421 - accuracy: 0.7313Epoch 12/15\n",
      "558/891 [=================>............] - ETA: 19s - loss: 13.7111 - accuracy: 0.0995Epoch 12/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.2618 - accuracy: 0.9512 - val_loss: 0.5097 - val_accuracy: 0.9413\n",
      " 28/223 [==>...........................] - ETA: 10s - loss: 0.3081 - accuracy: 0.9121Epoch 12/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0811 - val_accuracy: 0.9763\n",
      "2553/3563 [====================>.........] - ETA: 1:00 - loss: 4.2328 - accuracy: 0.0978Epoch 12/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.4578 - accuracy: 0.8762 - val_loss: 0.4537 - val_accuracy: 0.8677\n",
      "2596/3563 [====================>.........] - ETA: 58s - loss: 0.3697 - accuracy: 0.8905Epoch 12/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.7419 - accuracy: 0.7314 - val_loss: 0.6912 - val_accuracy: 0.7323\n",
      " 713/1782 [===========>..................] - ETA: 1:03 - loss: 0.8214 - accuracy: 0.7479Epoch 12/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.1329 - accuracy: 0.5255 - val_loss: 1.1305 - val_accuracy: 0.5043\n",
      "2664/3563 [=====================>........] - ETA: 52s - loss: 70.2796 - accuracy: 0.1014Epoch 12/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.5791 - accuracy: 0.8451 - val_loss: 0.5591 - val_accuracy: 0.8503\n",
      "844/891 [===========================>..] - ETA: 2s - loss: 0.1841 - accuracy: 0.9489Epoch 12/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 1.0990 - accuracy: 0.7380 - val_loss: 1.3767 - val_accuracy: 0.7070\n",
      " 695/1782 [==========>...................] - ETA: 1:01 - loss: 6.7483 - accuracy: 0.1036Epoch 12/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 0.5901 - accuracy: 0.9111 - val_loss: 1.4281 - val_accuracy: 0.8887\n",
      "383/446 [========================>.....] - ETA: 3s - loss: 0.3194 - accuracy: 0.9255Epoch 4/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 0.1841 - accuracy: 0.9488 - val_loss: 0.1820 - val_accuracy: 0.9477\n",
      "159/223 [====================>.........] - ETA: 3s - loss: 0.2482 - accuracy: 0.953393Epoch 4/15\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.2780 - accuracy: 0.9221 - val_loss: 0.2883 - val_accuracy: 0.9220\n",
      " 810/1782 [============>.................] - ETA: 57s - loss: 0.8132 - accuracy: 0.7498Epoch 7/15\n",
      "891/891 [==============================] - 52s 58ms/step - loss: 0.1010 - accuracy: 0.9696 - val_loss: 0.1253 - val_accuracy: 0.9637\n",
      "2710/3563 [=====================>........] - ETA: 51s - loss: 0.3628 - accuracy: 0.8925Epoch 4/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 0.1593 - accuracy: 0.9534 - val_loss: 0.1746 - val_accuracy: 0.9510\n",
      "432/446 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.9033Epoch 4/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.1861 - accuracy: 0.9544 - val_loss: 0.3304 - val_accuracy: 0.9390\n",
      "325/446 [====================>.........] - ETA: 6s - loss: 2.3433 - accuracy: 0.10249Epoch 7/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.3132 - accuracy: 0.9097 - val_loss: 0.2976 - val_accuracy: 0.9150\n",
      "392/446 [=========================>....] - ETA: 3s - loss: 0.9280 - accuracy: 0.7178Epoch 13/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.3470 - accuracy: 0.9029 - val_loss: 0.4373 - val_accuracy: 0.8827\n",
      "  1/223 [..............................] - ETA: 12s - loss: 0.3771 - accuracy: 0.9023Epoch 7/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.0956 - val_accuracy: 0.9767\n",
      "222/223 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9531Epoch 7/15\n",
      "891/891 [==============================] - 54s 60ms/step - loss: 0.1248 - accuracy: 0.9645 - val_loss: 0.1641 - val_accuracy: 0.9543\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.2512 - accuracy: 0.9292 - val_loss: 0.2552 - val_accuracy: 0.9253\n",
      " 11/446 [..............................] - ETA: 21s - loss: 0.1445 - accuracy: 0.9517Epoch 13/15\n",
      "Epoch 4/15\n",
      "223/223 [==============================] - 12s 56ms/step - loss: 0.2572 - accuracy: 0.9531 - val_loss: 0.4630 - val_accuracy: 0.9420\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.3207 - accuracy: 0.9249 - val_loss: 0.4306 - val_accuracy: 0.9133\n",
      "2815/3563 [======================>.......] - ETA: 43s - loss: 1.0402 - accuracy: 0.8348Epoch 13/15\n",
      " 820/1782 [============>.................] - ETA: 55s - loss: 6.9379 - accuracy: 0.1025Epoch 7/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.0877 - val_accuracy: 0.9757\n",
      "2791/3563 [======================>.......] - ETA: 45s - loss: 0.3091 - accuracy: 0.9113Epoch 7/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.4976 - accuracy: 0.8642 - val_loss: 0.4963 - val_accuracy: 0.8480\n",
      "419/446 [===========================>..] - ETA: 1s - loss: 0.1417 - accuracy: 0.9589Epoch 7/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 16.7003 - accuracy: 0.1014 - val_loss: 17.2470 - val_accuracy: 0.1043\n",
      "2759/3563 [======================>.......] - ETA: 47s - loss: 4.2290 - accuracy: 0.0982Epoch 4/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0787 - val_accuracy: 0.9830\n",
      " 968/1782 [===============>..............] - ETA: 47s - loss: 0.1603 - accuracy: 0.9535Epoch 13/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.9189 - accuracy: 0.7214 - val_loss: 0.8308 - val_accuracy: 0.7413\n",
      "2724/3563 [=====================>........] - ETA: 50s - loss: 0.6270 - accuracy: 0.8485Epoch 7/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.4372 - accuracy: 0.8811 - val_loss: 0.4363 - val_accuracy: 0.8687\n",
      "2746/3563 [======================>.......] - ETA: 49s - loss: 2.3571 - accuracy: 0.1018Epoch 13/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.1409 - accuracy: 0.9591 - val_loss: 0.1770 - val_accuracy: 0.9503\n",
      "2797/3563 [======================>.......] - ETA: 45s - loss: 4.2284 - accuracy: 0.0983Epoch 7/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.7376 - accuracy: 0.7336 - val_loss: 0.7238 - val_accuracy: 0.7407\n",
      "130/446 [=======>......................] - ETA: 19s - loss: 0.2695 - accuracy: 0.92475Epoch 13/15\n",
      "891/891 [==============================] - 54s 61ms/step - loss: 21.9522 - accuracy: 0.1006 - val_loss: 26.5753 - val_accuracy: 0.1047\n",
      "  9/223 [>.............................] - ETA: 10s - loss: 0.7179 - accuracy: 0.7574Epoch 4/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.1044 - accuracy: 0.5465 - val_loss: 1.2103 - val_accuracy: 0.5000\n",
      " 22/446 [>.............................] - ETA: 24s - loss: 0.1399 - accuracy: 0.9602Epoch 13/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.5787 - accuracy: 0.8476 - val_loss: 0.4221 - val_accuracy: 0.8860\n",
      " 27/446 [>.............................] - ETA: 24s - loss: 0.1392 - accuracy: 0.9606Epoch 13/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.0610 - accuracy: 0.7466 - val_loss: 1.5627 - val_accuracy: 0.5807\n",
      "1103/1782 [=================>............] - ETA: 38s - loss: 0.1778 - accuracy: 0.9519Epoch 13/15\n",
      "891/891 [==============================] - 54s 60ms/step - loss: 13.9580 - accuracy: 0.0989 - val_loss: 12.3655 - val_accuracy: 0.0910\n",
      " 58/223 [======>.......................] - ETA: 9s - loss: 0.4307 - accuracy: 0.8848Epoch 4/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 2.3430 - accuracy: 0.1023 - val_loss: 2.3257 - val_accuracy: 0.1020\n",
      " 43/891 [>.............................] - ETA: 51s - loss: 21.7912 - accuracy: 0.0930Epoch 7/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.3082 - accuracy: 0.9119 - val_loss: 0.2904 - val_accuracy: 0.9150\n",
      "1102/1782 [=================>............] - ETA: 40s - loss: 0.1745 - accuracy: 0.9477Epoch 14/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.2442 - accuracy: 0.9312 - val_loss: 0.2490 - val_accuracy: 0.9273\n",
      "3012/3563 [========================>.....] - ETA: 32s - loss: 0.5880 - accuracy: 0.8516Epoch 14/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.2423 - accuracy: 0.9541 - val_loss: 0.5416 - val_accuracy: 0.9483\n",
      "1234/1782 [===================>..........] - ETA: 31s - loss: 0.1812 - accuracy: 0.9513Epoch 14/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.4207 - accuracy: 0.8845 - val_loss: 0.4187 - val_accuracy: 0.8753\n",
      "363/891 [===========>..................] - ETA: 30s - loss: 0.1616 - accuracy: 0.9543Epoch 14/15\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0923 - val_accuracy: 0.9773\n",
      "1255/1782 [====================>.........] - ETA: 30s - loss: 0.7550 - accuracy: 0.8125Epoch 14/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.7359 - accuracy: 0.7336 - val_loss: 0.6706 - val_accuracy: 0.7563\n",
      "302/446 [===================>..........] - ETA: 8s - loss: 0.0456 - accuracy: 0.9849Epoch 14/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 1.1169 - accuracy: 0.5467 - val_loss: 1.1127 - val_accuracy: 0.5390\n",
      "311/446 [===================>..........] - ETA: 7s - loss: 0.4567 - accuracy: 0.8741Epoch 14/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.5267 - accuracy: 0.8580 - val_loss: 0.6917 - val_accuracy: 0.8317\n",
      "3151/3563 [=========================>....] - ETA: 24s - loss: 70.2144 - accuracy: 0.1013Epoch 14/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 1.4035 - accuracy: 0.7177 - val_loss: 3.0731 - val_accuracy: 0.6740\n",
      "283/446 [==================>...........] - ETA: 9s - loss: 0.1279 - accuracy: 0.9626Epoch 14/15\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.2689 - accuracy: 0.9251 - val_loss: 0.2834 - val_accuracy: 0.9233\n",
      "3135/3563 [=========================>....] - ETA: 25s - loss: 0.2542 - accuracy: 0.9227Epoch 8/15\n",
      "223/223 [==============================] - 13s 56ms/step - loss: 0.3047 - accuracy: 0.9121 - val_loss: 0.2882 - val_accuracy: 0.9167\n",
      "1374/1782 [======================>.......] - ETA: 23s - loss: 0.1535 - accuracy: 0.9563Epoch 15/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.1858 - accuracy: 0.9542 - val_loss: 0.3512 - val_accuracy: 0.9437\n",
      "141/223 [=================>............] - ETA: 4s - loss: 0.0150 - accuracy: 0.9952Epoch 8/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.3787 - accuracy: 0.8921 - val_loss: 0.3995 - val_accuracy: 0.8837\n",
      "439/446 [============================>.] - ETA: 0s - loss: 0.4529 - accuracy: 0.875207Epoch 8/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.2374 - accuracy: 0.9334 - val_loss: 0.2419 - val_accuracy: 0.9300\n",
      "3095/3563 [=========================>....] - ETA: 28s - loss: 14.7354 - accuracy: 0.1004Epoch 15/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.0511 - accuracy: 0.9840 - val_loss: 0.1156 - val_accuracy: 0.9730\n",
      " 24/223 [==>...........................] - ETA: 10s - loss: 0.3133 - accuracy: 0.9089Epoch 8/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.3240 - accuracy: 0.9242 - val_loss: 0.3598 - val_accuracy: 0.9227\n",
      " 13/446 [..............................] - ETA: 26s - loss: 0.4418 - accuracy: 0.8690Epoch 8/15\n",
      "446/446 [==============================] - 26s 59ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.0996 - val_accuracy: 0.9737\n",
      "1421/1782 [======================>.......] - ETA: 20s - loss: 0.1252 - accuracy: 0.9625Epoch 8/15\n",
      "446/446 [==============================] - 26s 58ms/step - loss: 0.4518 - accuracy: 0.8755 - val_loss: 0.4342 - val_accuracy: 0.8787\n",
      "1403/1782 [======================>.......] - ETA: 22s - loss: 0.1530 - accuracy: 0.9563Epoch 8/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.2415 - accuracy: 0.9551 - val_loss: 0.4375 - val_accuracy: 0.9537\n",
      " 12/446 [..............................] - ETA: 28s - loss: 0.2543 - accuracy: 0.9349Epoch 15/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.4068 - accuracy: 0.8879 - val_loss: 0.4065 - val_accuracy: 0.8753\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.7909 - accuracy: 0.7654 - val_loss: 0.7221 - val_accuracy: 0.7907\n",
      "1486/1782 [========================>.....] - ETA: 16s - loss: 0.1256 - accuracy: 0.9627Epoch 15/15\n",
      "204/223 [==========================>...] - ETA: 1s - loss: 1.1072 - accuracy: 0.548610Epoch 8/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 0.1240 - accuracy: 0.9635 - val_loss: 0.1531 - val_accuracy: 0.9567\n",
      " 67/446 [===>..........................] - ETA: 22s - loss: 0.2990 - accuracy: 0.9305Epoch 8/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1053 - val_accuracy: 0.9753\n",
      "1401/1782 [======================>.......] - ETA: 22s - loss: 1.0190 - accuracy: 0.6555Epoch 15/15\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.7359 - accuracy: 0.7358 - val_loss: 0.7456 - val_accuracy: 0.7353\n",
      "1494/1782 [========================>.....] - ETA: 16s - loss: 0.7259 - accuracy: 0.8179Epoch 15/15\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 1.1012 - accuracy: 0.5503 - val_loss: 1.0764 - val_accuracy: 0.5477\n",
      "201/223 [==========================>...] - ETA: 1s - loss: 1.3385 - accuracy: 0.7317Epoch 15/15\n",
      "223/223 [==============================] - 13s 60ms/step - loss: 0.6063 - accuracy: 0.8361 - val_loss: 0.5821 - val_accuracy: 0.8027\n",
      "101/223 [============>.................] - ETA: 6s - loss: 0.2202 - accuracy: 0.9570Epoch 15/15\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 1.3716 - accuracy: 0.7237 - val_loss: 1.4339 - val_accuracy: 0.7383\n",
      "1592/1782 [=========================>....] - ETA: 10s - loss: 0.1843 - accuracy: 0.9512Epoch 15/15\n",
      "446/446 [==============================] - 27s 60ms/step - loss: 2.3374 - accuracy: 0.1012 - val_loss: 2.3333 - val_accuracy: 0.1083\n",
      "1598/1782 [=========================>....] - ETA: 10s - loss: 0.1840 - accuracy: 0.9512Epoch 8/15\n",
      "223/223 [==============================] - 13s 58ms/step - loss: 0.3015 - accuracy: 0.9137 - val_loss: 0.2888 - val_accuracy: 0.9147\n",
      "223/223 [==============================] - 13s 59ms/step - loss: 0.2311 - accuracy: 0.9348 - val_loss: 0.2368 - val_accuracy: 0.9293\n",
      "223/223 [==============================] - 14s 61ms/step - loss: 0.2322 - accuracy: 0.9554 - val_loss: 0.4301 - val_accuracy: 0.9507\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.3954 - accuracy: 0.8898 - val_loss: 0.3959 - val_accuracy: 0.8783\n",
      "223/223 [==============================] - 14s 62ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0732 - val_accuracy: 0.9813\n",
      "223/223 [==============================] - 15s 65ms/step - loss: 0.6657 - accuracy: 0.7916 - val_loss: 0.6554 - val_accuracy: 0.8087\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 1.1266 - accuracy: 0.5411 - val_loss: 1.1591 - val_accuracy: 0.5137\n",
      "223/223 [==============================] - 14s 63ms/step - loss: 0.5542 - accuracy: 0.8576 - val_loss: 0.5553 - val_accuracy: 0.8353\n",
      "223/223 [==============================] - 14s 65ms/step - loss: 1.3641 - accuracy: 0.7351 - val_loss: 1.1590 - val_accuracy: 0.7110\n",
      "1782/1782 [==============================] - 105s 59ms/step - loss: 0.1836 - accuracy: 0.9519 - val_loss: 0.2244 - val_accuracy: 0.9450\n",
      "1704/1782 [===========================>..] - ETA: 4s - loss: 1.0749 - accuracy: 0.6257Epoch 3/15\n",
      "891/891 [==============================] - 54s 60ms/step - loss: 0.5282 - accuracy: 0.9206 - val_loss: 0.5464 - val_accuracy: 0.9283\n",
      "1631/1782 [==========================>...] - ETA: 8s - loss: 6.7600 - accuracy: 0.1038Epoch 5/15\n",
      "703/891 [======================>.......] - ETA: 11s - loss: 13.4518 - accuracy: 0.1003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/446 [===================>..........] - ETA: 8s - loss: 0.1094 - accuracy: 0.967710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645/1782 [==========================>...] - ETA: 8s - loss: 0.1889 - accuracy: 0.9444[I 2024-04-06 13:57:24,068] Trial 25 finished with value: 0.9178000092506409 and parameters: {'learning_rate': 0.09577016214246162, 'batch_size': 256, 'optimizer': 0, 'activation': 'sigmoid', 'activation_out': 'softmax', 'n_layers': 1, 'n_neurons_0': 766}. Best is trial 25 with value: 0.9178000092506409.\n",
      "831/891 [==========================>...] - ETA: 3s - loss: 16.1896 - accuracy: 0.1010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [04:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/446 [===================>..........] - ETA: 8s - loss: 0.7027 - accuracy: 0.7996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.9178:   0%|          | 0/100 [04:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/446 [=======================>......] - ETA: 5s - loss: 0.4230 - accuracy: 0.881606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.9178:   1%|          | 1/100 [04:07<6:48:35, 247.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 27s 60ms/step - loss: 0.2611 - accuracy: 0.9272 - val_loss: 0.2737 - val_accuracy: 0.9243\n",
      "Epoch 9/15\n",
      "891/891 [==============================] - 53s 59ms/step - loss: 0.0848 - accuracy: 0.9740 - val_loss: 0.1242 - val_accuracy: 0.9617\n",
      "Epoch 5/15\n",
      "891/891 [==============================] - 54s 60ms/step - loss: 0.1524 - accuracy: 0.9577 - val_loss: 0.1626 - val_accuracy: 0.9527\n",
      "3467/3563 [============================>.] - ETA: 5s - loss: 14.6618 - accuracy: 0.1002Epoch 5/15\n",
      "1782/1782 [==============================] - 105s 59ms/step - loss: 0.5952 - accuracy: 0.8617 - val_loss: 0.9477 - val_accuracy: 0.8057\n",
      "  14/1782 [..............................] - ETA: 2:14 - loss: 0.1599 - accuracy: 0.9643Epoch 3/15\n",
      "891/891 [==============================] - 53s 59ms/step - loss: 0.1273 - accuracy: 0.9625 - val_loss: 0.1428 - val_accuracy: 0.9607\n",
      "757/891 [========================>.....] - ETA: 8s - loss: 22.0248 - accuracy: 0.0996Epoch 5/15\n",
      "863/891 [============================>.] - ETA: 1s - loss: 0.1067 - accuracy: 0.9697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650/1782 [==========================>...] - ETA: 7s - loss: 6.7687 - accuracy: 0.1036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.9178:   1%|          | 1/100 [04:09<6:48:35, 247.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-04-06 13:57:25,503] Trial 35 finished with value: 0.9358000159263611 and parameters: {'learning_rate': 0.04026554558502399, 'batch_size': 256, 'optimizer': 0, 'activation': 'tanh', 'activation_out': 'softmax', 'n_layers': 1, 'n_neurons_0': 102}. Best is trial 35 with value: 0.9358000159263611.\n",
      " 22/446 [>.............................] - ETA: 21s - loss: 0.2562 - accuracy: 0.92830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.9358:   1%|          | 1/100 [04:09<6:48:35, 247.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/891 [..............................] - ETA: 50s - loss: 0.0897 - accuracy: 0.9771551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.9358:   2%|▏         | 2/100 [04:09<2:47:56, 102.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 107s 60ms/step - loss: 0.1254 - accuracy: 0.9625 - val_loss: 0.1268 - val_accuracy: 0.9537\n",
      "1749/1782 [============================>.] - ETA: 1s - loss: 0.1638 - accuracy: 0.9508Epoch 3/15\n",
      "420/446 [===========================>..] - ETA: 1s - loss: 0.0490 - accuracy: 0.984176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740/1782 [============================>.] - ETA: 2s - loss: 1.0766 - accuracy: 0.6242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/446 [==========================>...] - ETA: 2s - loss: 0.0519 - accuracy: 0.9841[I 2024-04-06 13:57:26,432] Trial 28 finished with value: 0.9477999806404114 and parameters: {'learning_rate': 0.08114706720447636, 'batch_size': 256, 'optimizer': 2, 'activation': 'relu', 'activation_out': 'sigmoid', 'n_layers': 1, 'n_neurons_0': 989}. Best is trial 28 with value: 0.9477999806404114.\n",
      "1782/1782 [==============================] - 108s 61ms/step - loss: 0.6955 - accuracy: 0.8243 - val_loss: 0.5118 - val_accuracy: 0.8627\n",
      "  26/1782 [..............................] - ETA: 1:45 - loss: 0.6516 - accuracy: 0.8690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.9358:   2%|▏         | 2/100 [04:09<2:47:56, 102.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1782 [===========================>..] - ETA: 6s - loss: 6.7660 - accuracy: 0.1036Epoch 3/15\n",
      "1782/1782 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   2%|▏         | 2/100 [04:10<2:47:56, 102.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3563/3563 [==============================] - 237s 61ms/step - loss: 70.2107 - accuracy: 0.1006 - val_loss: 51.8038 - val_accuracy: 0.0943\n",
      "   2/1782 [..............................] - ETA: 2:30 - loss: 0.3041 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   3%|▎         | 3/100 [04:10<1:31:04, 56.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40/446 [=>............................] - ETA: 23s - loss: 0.2448 - accuracy: 0.9307Epoch 2/15\n",
      "3563/3563 [==============================] - 238s 61ms/step - loss: 1.0508 - accuracy: 0.8438 - val_loss: 1.0137 - val_accuracy: 0.8873\n",
      "   2/1782 [..............................] - ETA: 1:50 - loss: 0.4540 - accuracy: 0.9062Epoch 2/15\n",
      "3563/3563 [==============================] - 237s 61ms/step - loss: 7.0541 - accuracy: 0.7001 - val_loss: 9.7470 - val_accuracy: 0.7147\n",
      "  30/1782 [..............................] - ETA: 1:53 - loss: 0.6269 - accuracy: 0.8698Epoch 2/15\n",
      "3563/3563 [==============================] - 238s 60ms/step - loss: 0.6059 - accuracy: 0.8522 - val_loss: 1.1195 - val_accuracy: 0.7840\n",
      "352/446 [======================>.......] - ETA: 5s - loss: 0.6968 - accuracy: 0.801016Epoch 2/15\n",
      "3563/3563 [==============================] - 238s 61ms/step - loss: 0.2849 - accuracy: 0.9180 - val_loss: 0.1934 - val_accuracy: 0.9420\n",
      "291/446 [==================>...........] - ETA: 9s - loss: 2.3394 - accuracy: 0.1026Epoch 2/15\n",
      "446/446 [==============================] - 28s 62ms/step - loss: 0.3641 - accuracy: 0.8979 - val_loss: 0.4428 - val_accuracy: 0.8730\n",
      "  21/3563 [..............................] - ETA: 3:30 - loss: 0.8335 - accuracy: 0.8214Epoch 9/15\n",
      "446/446 [==============================] - 27s 61ms/step - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.1081 - val_accuracy: 0.9710\n",
      "3563/3563 [==============================] - 240s 62ms/step - loss: 0.3233 - accuracy: 0.9045 - val_loss: 0.1624 - val_accuracy: 0.9540\n",
      "379/446 [========================>.....] - ETA: 4s - loss: 0.6936 - accuracy: 0.8020Epoch 9/15\n",
      "Epoch 2/15\n",
      "446/446 [==============================] - 29s 64ms/step - loss: 0.1882 - accuracy: 0.9557 - val_loss: 0.3522 - val_accuracy: 0.9420\n",
      " 80/891 [=>............................] - ETA: 51s - loss: 0.4527 - accuracy: 0.9291Epoch 9/15\n",
      "1782/1782 [==============================] - 109s 61ms/step - loss: 0.1475 - accuracy: 0.9579 - val_loss: 0.1420 - val_accuracy: 0.9587\n",
      "  1/446 [..............................] - ETA: 35s - loss: 0.1394 - accuracy: 0.9609Epoch 3/15\n",
      "891/891 [==============================] - 55s 61ms/step - loss: 0.1063 - accuracy: 0.9698 - val_loss: 0.1474 - val_accuracy: 0.9637\n",
      "  38/3563 [..............................] - ETA: 3:27 - loss: 5.7206 - accuracy: 0.8174Epoch 5/15\n",
      "446/446 [==============================] - 28s 64ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.1011 - val_accuracy: 0.9773\n",
      " 12/446 [..............................] - ETA: 27s - loss: 0.0419 - accuracy: 0.9837Epoch 9/15\n",
      "891/891 [==============================] - 53s 60ms/step - loss: 16.2029 - accuracy: 0.1008 - val_loss: 19.2797 - val_accuracy: 0.0860\n",
      "  54/1782 [..............................] - ETA: 1:39 - loss: 0.5312 - accuracy: 0.8605Epoch 5/15\n",
      "1782/1782 [==============================] - 108s 61ms/step - loss: 0.1472 - accuracy: 0.9570 - val_loss: 0.1089 - val_accuracy: 0.9677\n",
      " 71/891 [=>............................] - ETA: 50s - loss: 0.1118 - accuracy: 0.968501Epoch 3/15\n",
      "829/891 [==========================>...] - ETA: 3s - loss: 22.0703 - accuracy: 0.0989083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/891 [==>...........................] - ETA: 49s - loss: 0.4530 - accuracy: 0.930260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/891 [..............................] - ETA: 1:14 - loss: 17.1311 - accuracy: 0.1172[I 2024-04-06 13:57:29,894] Trial 15 finished with value: 0.8960999846458435 and parameters: {'learning_rate': 0.03993595880621893, 'batch_size': 256, 'optimizer': 0, 'activation': 'sigmoid', 'activation_out': 'softmax', 'n_layers': 2, 'n_neurons_0': 835, 'n_neurons_1': 243}. Best is trial 28 with value: 0.9477999806404114.\n",
      "  56/1782 [..............................] - ETA: 1:46 - loss: 0.1077 - accuracy: 0.9715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   3%|▎         | 3/100 [04:13<1:31:04, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/891 [..............................] - ETA: 45s - loss: 0.0740 - accuracy: 0.981267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   3%|▎         | 3/100 [04:13<1:31:04, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720/1782 [===========================>..] - ETA: 3s - loss: 6.6850 - accuracy: 0.103974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   4%|▍         | 4/100 [04:13<56:41, 35.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 29s 64ms/step - loss: 0.3151 - accuracy: 0.9287 - val_loss: 0.4506 - val_accuracy: 0.9197\n",
      "  45/3563 [..............................] - ETA: 3:45 - loss: 0.7245 - accuracy: 0.8375Epoch 9/15\n",
      "446/446 [==============================] - 28s 63ms/step - loss: 0.4215 - accuracy: 0.8823 - val_loss: 0.4170 - val_accuracy: 0.8807\n",
      " 96/891 [==>...........................] - ETA: 48s - loss: 0.0669 - accuracy: 0.97903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798/891 [=========================>....] - ETA: 5s - loss: 13.7181 - accuracy: 0.0991[I 2024-04-06 13:57:30,352] Trial 31 finished with value: 0.9783999919891357 and parameters: {'learning_rate': 0.021215747254235067, 'batch_size': 256, 'optimizer': 2, 'activation': 'sigmoid', 'activation_out': 'sigmoid', 'n_layers': 2, 'n_neurons_0': 488, 'n_neurons_1': 758}. Best is trial 31 with value: 0.9783999919891357.\n",
      "Epoch 9/15\n",
      "835/891 [===========================>..] - ETA: 3s - loss: 22.0851 - accuracy: 0.0991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.9478:   4%|▍         | 4/100 [04:13<56:41, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/446 [=========================>....] - ETA: 2s - loss: 0.6923 - accuracy: 0.8024.089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   4%|▍         | 4/100 [04:13<56:41, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/446 [======>.......................] - ETA: 19s - loss: 0.2457 - accuracy: 0.930871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   5%|▌         | 5/100 [04:13<36:06, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803/891 [==========================>...] - ETA: 5s - loss: 13.7127 - accuracy: 0.099266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/891 [===========================>..] - ETA: 3s - loss: 22.0791 - accuracy: 0.099271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/891 [..............................] - ETA: 1:15 - loss: 17.3390 - accuracy: 0.0923[I 2024-04-06 13:57:30,688] Trial 26 finished with value: 0.8185999989509583 and parameters: {'learning_rate': 0.04986573997667837, 'batch_size': 256, 'optimizer': 2, 'activation': 'relu', 'activation_out': 'sigmoid', 'n_layers': 2, 'n_neurons_0': 149, 'n_neurons_1': 733}. Best is trial 31 with value: 0.9783999919891357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   5%|▌         | 5/100 [04:14<36:06, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3563/3563 [==============================] - 242s 61ms/step - loss: 4.2268 - accuracy: 0.0983 - val_loss: 4.6209 - val_accuracy: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   5%|▌         | 5/100 [04:14<36:06, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/1782 [..............................] - ETA: 2:20 - loss: 0.1957 - accuracy: 0.9406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   6%|▌         | 6/100 [04:14<23:45, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/891 [..............................] - ETA: 1:06 - loss: 16.6518 - accuracy: 0.0904Epoch 2/15\n",
      "3563/3563 [==============================] - 242s 62ms/step - loss: 0.2420 - accuracy: 0.9266 - val_loss: 0.1517 - val_accuracy: 0.9547\n",
      "Epoch 2/15\n",
      " 33/446 [=>............................] - ETA: 27s - loss: 0.1718 - accuracy: 0.958374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  62/3563 [..............................] - ETA: 3:45 - loss: 0.1817 - accuracy: 0.9506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/891 [==>...........................] - ETA: 48s - loss: 0.1070 - accuracy: 0.9696[I 2024-04-06 13:57:31,235] Trial 29 finished with value: 0.5321000218391418 and parameters: {'learning_rate': 0.070654497678556, 'batch_size': 256, 'optimizer': 2, 'activation': 'relu', 'activation_out': 'sigmoid', 'n_layers': 3, 'n_neurons_0': 680, 'n_neurons_1': 375, 'n_neurons_2': 310}. Best is trial 31 with value: 0.9783999919891357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   6%|▌         | 6/100 [04:14<23:45, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37/891 [>.............................] - ETA: 49s - loss: 0.0798 - accuracy: 0.977208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   6%|▌         | 6/100 [04:14<23:45, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/891 [..............................] - ETA: 1:01 - loss: 16.5714 - accuracy: 0.0966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   7%|▋         | 7/100 [04:14<16:07, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 109s 61ms/step - loss: 0.1637 - accuracy: 0.9509 - val_loss: 0.1714 - val_accuracy: 0.9473\n",
      "  78/3563 [..............................] - ETA: 3:27 - loss: 5.6976 - accuracy: 0.8069Epoch 3/15\n",
      "118/891 [==>...........................] - ETA: 46s - loss: 0.1287 - accuracy: 0.963617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/446 [=======>......................] - ETA: 17s - loss: 0.2493 - accuracy: 0.9305092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/446 [=>............................] - ETA: 25s - loss: 0.0506 - accuracy: 0.983051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   7%|▋         | 7/100 [04:15<16:07, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/446 [=>............................] - ETA: 23s - loss: 0.0513 - accuracy: 0.9830[I 2024-04-06 13:57:31,766] Trial 8 finished with value: 0.8314999938011169 and parameters: {'learning_rate': 0.02542427201167166, 'batch_size': 256, 'optimizer': 1, 'activation': 'tanh', 'activation_out': 'sigmoid', 'n_layers': 2, 'n_neurons_0': 635, 'n_neurons_1': 358}. Best is trial 31 with value: 0.9783999919891357.\n",
      " 29/891 [..............................] - ETA: 1:00 - loss: 16.1862 - accuracy: 0.0921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   7%|▋         | 7/100 [04:15<16:07, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27/1782 [..............................] - ETA: 2:00 - loss: 0.1438 - accuracy: 0.9537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   8%|▊         | 8/100 [04:15<11:06,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 108s 61ms/step - loss: 1.0779 - accuracy: 0.6221 - val_loss: 1.4890 - val_accuracy: 0.4607\n",
      "  31/1782 [..............................] - ETA: 1:58 - loss: 0.1359 - accuracy: 0.9577Epoch 3/15\n",
      "157/446 [=========>....................] - ETA: 15s - loss: 0.2538 - accuracy: 0.928976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  36/3563 [..............................] - ETA: 3:35 - loss: 0.1556 - accuracy: 0.9566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70/1782 [>.............................] - ETA: 1:36 - loss: 0.1081 - accuracy: 0.9638I 2024-04-06 13:57:33,080] Trial 40 finished with value: 0.7077999711036682 and parameters: {'learning_rate': 0.043252163268706866, 'batch_size': 256, 'optimizer': 1, 'activation': 'tanh', 'activation_out': 'sigmoid', 'n_layers': 2, 'n_neurons_0': 376, 'n_neurons_1': 576}. Best is trial 31 with value: 0.9783999919891357\n",
      "  39/3563 [..............................] - ETA: 3:22 - loss: 4.1343 - accuracy: 0.0978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   8%|▊         | 8/100 [04:16<11:06,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/891 [====>.........................] - ETA: 42s - loss: 0.0666 - accuracy: 0.979561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   8%|▊         | 8/100 [04:16<11:06,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 109/1782 [>.............................] - ETA: 1:40 - loss: 0.5360 - accuracy: 0.8578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.9784:   9%|▉         | 9/100 [04:16<08:12,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 28s 64ms/step - loss: 0.1100 - accuracy: 0.9677 - val_loss: 0.1423 - val_accuracy: 0.9610\n",
      "396/446 [=========================>....] - ETA: 3s - loss: 2.3393 - accuracy: 0.101496Epoch 9/15\n",
      "446/446 [==============================] - 29s 65ms/step - loss: 0.6866 - accuracy: 0.8046 - val_loss: 0.6239 - val_accuracy: 0.8327\n",
      "  88/1782 [>.............................] - ETA: 1:32 - loss: 0.1098 - accuracy: 0.9634Epoch 9/15\n",
      "3563/3563 [==============================] - 245s 62ms/step - loss: 2.3471 - accuracy: 0.1023 - val_loss: 2.3139 - val_accuracy: 0.0963\n",
      "151/891 [====>.........................] - ETA: 43s - loss: 0.1087 - accuracy: 0.9698Epoch 2/15\n",
      "179/891 [=====>........................] - ETA: 40s - loss: 0.1345 - accuracy: 0.9624dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1', 'n_neurons_2'])\n",
      "3563/3563 [==============================] - 246s 62ms/step - loss: 0.5943 - accuracy: 0.8576 - val_loss: 0.4243 - val_accuracy: 0.9017\n",
      " 86/446 [====>.........................] - ETA: 19s - loss: 0.3915 - accuracy: 0.8949Epoch 2/15\n",
      "891/891 [==============================] - 56s 62ms/step - loss: 22.0637 - accuracy: 0.0993 - val_loss: 19.0660 - val_accuracy: 0.0970\n",
      "198/891 [=====>........................] - ETA: 38s - loss: 0.0657 - accuracy: 0.9804Epoch 5/15\n",
      " 156/1782 [=>............................] - ETA: 1:36 - loss: 0.0864 - accuracy: 0.9748dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      " 151/3563 [>.............................] - ETA: 3:22 - loss: 71.4122 - accuracy: 0.0898dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      " 29/446 [>.............................] - ETA: 29s - loss: 0.6396 - accuracy: 0.814409Epoch 1/15\n",
      "181/891 [=====>........................] - ETA: 43s - loss: 0.1101 - accuracy: 0.9697Epoch 1/15\n",
      "Epoch 1/15\n",
      " 159/3563 [>.............................] - ETA: 3:26 - loss: 0.6758 - accuracy: 0.8502dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0', 'n_neurons_1'])\n",
      "1782/1782 [==============================] - 110s 62ms/step - loss: 0.1894 - accuracy: 0.9444 - val_loss: 0.1671 - val_accuracy: 0.9457\n",
      " 133/1782 [=>............................] - ETA: 1:40 - loss: 0.1038 - accuracy: 0.9678Epoch 3/15\n",
      "1782/1782 [==============================] - 110s 62ms/step - loss: 6.6556 - accuracy: 0.1033 - val_loss: 6.1459 - val_accuracy: 0.0957\n",
      "124/446 [=======>......................] - ETA: 19s - loss: 0.3320 - accuracy: 0.9286Epoch 1/15\n",
      " 182/1782 [==>...........................] - ETA: 1:37 - loss: 0.5320 - accuracy: 0.8547Epoch 3/15\n",
      "3563/3563 [==============================] - 249s 63ms/step - loss: 14.5803 - accuracy: 0.1002 - val_loss: 16.3116 - val_accuracy: 0.1133\n",
      " 143/1782 [=>............................] - ETA: 1:42 - loss: 0.1031 - accuracy: 0.9679Epoch 2/15\n",
      " 179/3563 [>.............................] - ETA: 3:25 - loss: 0.1664 - accuracy: 0.9532dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      "891/891 [==============================] - 57s 64ms/step - loss: 13.7725 - accuracy: 0.1001 - val_loss: 16.6301 - val_accuracy: 0.0907\n",
      "124/446 [=======>......................] - ETA: 20s - loss: 0.3932 - accuracy: 0.891953Epoch 5/15\n",
      "126/446 [=======>......................] - ETA: 20s - loss: 0.3927 - accuracy: 0.8920dict_keys(['learning_rate', 'batch_size', 'optimizer', 'activation', 'activation_out', 'n_layers', 'n_neurons_0'])\n",
      " 120/3563 [>.............................] - ETA: 3:45 - loss: 4.1994 - accuracy: 0.0964"
     ]
    }
   ],
   "source": [
    "# 1) Criar um estudo (tarefa de otimização / conjunto de tentativas)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# 2) Definir uma função objetivo a ser otimizada\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "# 3) Plotar o gráfico de importância dos parâmetros\n",
    "plot_param_importances(study)\n",
    "\n",
    "date = pd.Timestamp.now().strftime(\"%d%m%Y_%H:%M:%S\")\n",
    "plt.savefig(f\"importances_{date}.png\")\n",
    "\n",
    "print(f\"Numero de otimizacoes realizadas: {len(study.trials)}\")\n",
    "\n",
    "print(\"Melhor resultado:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Acc: {trial.value}\")\n",
    "\n",
    "print(\"  Params: \")\n",
    "optims = [\"SGD\", \"Adam\", \"RMSprop\"]\n",
    "for key, value in trial.params.items():\n",
    "    if key != \"optimizer\":\n",
    "      print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "      print(f\"    {key}: {optims[value]}\")\n",
    "\n",
    "# 4) Tratar o DataFrame final e salvar os resultados\n",
    "res_df = study.trials_dataframe()\n",
    "columns = [c for c in res_df.keys() if c.startswith(\"params_\")] + [\"value\"]\n",
    "res_df[\"params_optimizer\"] = res_df[\"params_optimizer\"].apply(lambda x: optims[x])\n",
    "res_df.columns = [c.replace(\"params_\", \"\") for c in res_df.columns]\n",
    "csv_path = f\"optuna_{date}.csv\"\n",
    "res_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Oz-4hLRKK-R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2cf53f266da242daaf6e3af89560bb7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8a61a4845a34a3fb66cab88b6d0ec37",
      "placeholder": "​",
      "style": "IPY_MODEL_5951c2490dcd43fba7d8cead084c5938",
      "value": " 20/20 [13:14&lt;00:00, 56.76s/it]"
     }
    },
    "5951c2490dcd43fba7d8cead084c5938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6652cc9bc6164d0385b2c57c3a41269f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d4ee057b82346d78ffed0f23219e017",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc3bdcb9eaf140a1995ab621b9e21f1b",
      "value": 20
     }
    },
    "6d1df215490c432297f7f783b6cefc8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d4ee057b82346d78ffed0f23219e017": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8183f0f24ebc4a099e7170da3557ecf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b19e92ffd929457fa2f9b00adfadc22d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c62a84f300ee40f38cfcf8627059a295",
       "IPY_MODEL_6652cc9bc6164d0385b2c57c3a41269f",
       "IPY_MODEL_2cf53f266da242daaf6e3af89560bb7e"
      ],
      "layout": "IPY_MODEL_6d1df215490c432297f7f783b6cefc8d"
     }
    },
    "b8a61a4845a34a3fb66cab88b6d0ec37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6027eec729b40d98401d766ff0a90ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c62a84f300ee40f38cfcf8627059a295": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6027eec729b40d98401d766ff0a90ac",
      "placeholder": "​",
      "style": "IPY_MODEL_8183f0f24ebc4a099e7170da3557ecf2",
      "value": "Best trial: 15. Best value: 0.98: 100%"
     }
    },
    "dc3bdcb9eaf140a1995ab621b9e21f1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
