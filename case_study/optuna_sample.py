# -*- coding: utf-8 -*-
"""OptunaSample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c1dWUtWv2lRGLpJL-20OhjIzSWtbNXsc
"""

import optuna
from optuna.visualization.matplotlib import plot_param_importances
import matplotlib.pyplot as plt

import pandas as pd

import os
import tensorflow as tf
from tensorflow import keras
from keras.backend import clear_session
from keras.datasets import mnist
from keras.layers import MaxPool1D
from keras.callbacks import EarlyStopping
from keras.layers import Conv1D
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Input
from keras.models import Sequential
from sklearn.model_selection import train_test_split


CLASSES = 10
EPOCHS = 10

"""Função auxiliar para obtenção e separação dos dados em `train`, `test` e `valid`"""

def get_mnist():
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    img_x, img_y = x_test.shape[1], x_test.shape[2]
    x_train = x_train.reshape(-1, img_x, img_y, 1).astype("float32") / 255
    x_test = x_test.reshape(-1, img_x, img_y, 1).astype("float32") / 255

    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                      test_size=0.05)

    # print(f"train: {x_train.shape}")
    # print(f"val: {x_val.shape}")
    # print(f"test: {x_test.shape}")
    return (x_train, y_train), (x_val, y_val), (x_test, y_test)

"""Funções auxiliares para definição do espaço de busca paramétrico:


*   `get_config`: hiperparametrocos base, comum a todos os modelos
*   `get_cnn_config`: parâmetros específicos para modelo convolucional
*   `get_mlp_config`: parâmetros específicos para modelo totalmente conectado

Utiliza-se o objeto `trial`, que é instanciado e obtido após a chamada do `study.optimize`. O `trial` fornece funções como `suggest_float`, `suggest_categorical`, `suggest_int`, etc. Estas funções devem ser utilizadas de acordo com a característica do parâmetro a ser amostrado, e podem receber um range min/max do valores do parâmetro ou uma lista de categorias.


"""

def get_config(trial):
  config = {
      "learning_rate": trial.suggest_float("learning_rate", 1e-5, 1e-1),
      "batch_size": trial.suggest_categorical("batch_size", [16, 32, 64, 128, 256]),
      "optimizer": trial.suggest_categorical("optimizer", [0, 1, 2]),
      "activation": trial.suggest_categorical("activation",
       ["relu", "tanh", "sigmoid"]),
      "activation_out": trial.suggest_categorical("activation_out",
       ["softmax", "sigmoid"]),
  }

  return config


def get_cnn_config(trial):
  config = get_config(trial)
  config["n_hidden"] = trial.suggest_int("n_hidden", 1, 2)
  config["kernel_1"] = trial.suggest_categorical("kernel_1", [3, 5])
  config["kernel_2"] = trial.suggest_categorical("kernel_2", [3, 5])
  config["filters"] = trial.suggest_categorical("filters", [32, 64])
  config["stride"] = trial.suggest_categorical("stride", [1, 2])
  config["pool_size"] = trial.suggest_categorical("pool_size", [3, 5])

  return config


def get_mlp_config(trial):
  config = get_config(trial)
  config["n_neurons"] = trial.suggest_int("n_neurons", 32, 1024)

  return config


def get_optimizer(config):
    possible_optims = [
        tf.keras.optimizers.SGD(learning_rate=config["learning_rate"]),
        tf.keras.optimizers.Adam(learning_rate=config["learning_rate"]),
        tf.keras.optimizers.RMSprop(learning_rate=config["learning_rate"]),
    ]

    return possible_optims[config["optimizer"]]

"""Funções auxiliares para definição de dois modelos base:

*   Convolucional (`get_cnn`)
*   Totalmente conectado (`get_mlp`)


"""

def get_cnn(input_shape, config):
    model = Sequential()
    model.add(Input(shape=input_shape))
    model.add(Conv1D(
            filters=config["filters"],
            kernel_size=config["kernel_1"],
            activation=config["activation"])
    )
    model.add(Conv1D(
        filters=config["filters"],
        kernel_size=config["kernel_2"],
        activation=config["activation"],)
    )
    model.add(MaxPool1D(pool_size=config["pool_size"]))
    model.add(Flatten())
    model.add(Dense(CLASSES, activation="softmax"))

    return model

def get_mlp(config):
  model = Sequential()
  model.add(Flatten())
  model.add(Dense(config["n_neurons"], activation=config["activation"]))
  model.add(Dense(CLASSES, activation=config["activation_out"]))

  return model

"""### Definição da função objetivo
1. Obter os dados;
2. Definir configurações de espaço de busca paramêtrico;
3. Definir o modelo;
4. Treinar e avaliar;
"""

def objective(trial):
    clear_session()

    (x_train, y_train), (x_val, y_val), (x_test, y_test) = get_mnist()

    # input_shape = (x_train.shape[1], x_train.shape[2], 1)
    # configs = get_cnn_config(trial)
    # model = get_cnn(input_shape, configs)

    configs = get_mlp_config(trial)
    model = get_mlp(configs)

    optimizer = get_optimizer(configs)

    model.compile(
        loss="sparse_categorical_crossentropy",
        # loss="mse",
        optimizer=optimizer,
        metrics=["accuracy"],
    )

    monitor = EarlyStopping(
        monitor="val_loss",
        min_delta=1e-4,
        patience=10,
        verbose=0,
        mode="auto",
        restore_best_weights=True,
    )

    model.fit(
        x_train,
        y_train,
        validation_data=(x_val, y_val),
        shuffle=True,
        batch_size=configs["batch_size"],
        epochs=EPOCHS,
        verbose=True,
    )

    return model.evaluate(x_test, y_test, verbose=0)[1]

"""# Criação

1.   Criar um [`optuna.Study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study), utilizando a função [`create_study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.create_study.html).

  *   Um estudo corresponde a uma tarefa de otimização, i.e., um conjunto de tentativas.


2.   Definir uma função objetivo a ser otimizada, através da chamada do método [`optimize`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize) do objeto `optuna.Study`
   *   Definir os principais parametros como: função a ser otimizada (`objective`), número de tentativas (`n_trials`), número de jobs paralelos (`n_jobs`), etc.

   *   A função objetivo será executava `n_trials` vezes, até a conclusão da otimização como foi definida.

3. Plotar o gráfico de importância dos parâmetros através do [`plot_param_importances`](https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_param_importances.html) do pacote `optuna.visualization`

4. Tratar o dataframe final e salvar os resultados.


"""

# 1) Criar um estudo (tarefa de otimização / conjunto de tentativas)
study = optuna.create_study(direction="maximize")

# 2) Definir uma função objetivo a ser otimizada
study.optimize(objective, n_trials=2, n_jobs=-1, show_progress_bar=True)

# 3) Plotar o gráfico de importância dos parâmetros
plot_param_importances(study)

date = pd.Timestamp.now().strftime("%d%m%Y_%H:%M:%S")
plt.savefig(f"importances_{date}.png")

print(f"Number of finished trials: {len(study.trials)}")

print("Best trial:")
trial = study.best_trial

print(f"  Acc: {trial.value}")

print("  Params: ")
optims = ["SGD", "Adam", "RMSprop"]
for key, value in trial.params.items():
    if key != "optimizer":
      print(f"    {key}: {value}")
    else:
      print(f"    {key}: {optims[value]}")

# 4) Tratar o DataFrame final e salvar os resultados
res_df = study.trials_dataframe()
columns = [c for c in res_df.keys() if c.startswith("params_")] + ["value"]
res_df["params_optimizer"] = res_df["params_optimizer"].apply(lambda x: optims[x])
res_df.columns = [c.replace("params_", "") for c in res_df.columns]
csv_path = f"optuna_{date}.csv"
res_df.to_csv(csv_path, index=False)

